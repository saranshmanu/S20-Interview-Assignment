{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import print_summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_custom.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_final = Model(input = model.input, output = predictions)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               3276900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 17,991,790\n",
      "Trainable params: 3,277,102\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = 190\n",
    "train_count = 1000\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "Found 190 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "train = datagen.flow_from_directory('data/train/', class_mode='categorical', batch_size=batch_size)\n",
    "test = datagen.flow_from_directory('data/test/', class_mode='categorical', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "63/62 [==============================] - 10s 162ms/step - loss: 4.9527 - acc: 0.6548 - val_loss: 3.5553 - val_acc: 0.7632\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76316, saving model to vgg16_custom.h5\n",
      "Epoch 2/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 4.6683 - acc: 0.6845 - val_loss: 5.6840 - val_acc: 0.6368\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.76316\n",
      "Epoch 3/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 4.6653 - acc: 0.6935 - val_loss: 4.8705 - val_acc: 0.6474\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.76316\n",
      "Epoch 4/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 3.9570 - acc: 0.7341 - val_loss: 2.4786 - val_acc: 0.8105\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.76316 to 0.81053, saving model to vgg16_custom.h5\n",
      "Epoch 5/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 3.4623 - acc: 0.7629 - val_loss: 4.3118 - val_acc: 0.7211\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.81053\n",
      "Epoch 6/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 3.0521 - acc: 0.7768 - val_loss: 3.1377 - val_acc: 0.7684\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.81053\n",
      "Epoch 7/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 2.4058 - acc: 0.8036 - val_loss: 1.8604 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.81053 to 0.83684, saving model to vgg16_custom.h5\n",
      "Epoch 8/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 1.0103 - acc: 0.7976 - val_loss: 0.6157 - val_acc: 0.7789\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.83684\n",
      "Epoch 9/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.4635 - acc: 0.8006 - val_loss: 0.5244 - val_acc: 0.8105\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.83684\n",
      "Epoch 10/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.4071 - acc: 0.8333 - val_loss: 0.5076 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.83684 to 0.84211, saving model to vgg16_custom.h5\n",
      "Epoch 11/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.3601 - acc: 0.8482 - val_loss: 0.3965 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.84211 to 0.84211, saving model to vgg16_custom.h5\n",
      "Epoch 12/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.2990 - acc: 0.8522 - val_loss: 0.5161 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.84211\n",
      "Epoch 13/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.2702 - acc: 0.8700 - val_loss: 0.3927 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.84211 to 0.87368, saving model to vgg16_custom.h5\n",
      "Epoch 14/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.2768 - acc: 0.8979 - val_loss: 0.3829 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.87368\n",
      "Epoch 15/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.2102 - acc: 0.9077 - val_loss: 0.5416 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.87368\n",
      "Epoch 16/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.2007 - acc: 0.8939 - val_loss: 0.4223 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.87368\n",
      "Epoch 17/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1474 - acc: 0.9177 - val_loss: 0.5107 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.87368\n",
      "Epoch 18/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1585 - acc: 0.9206 - val_loss: 0.4252 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.87368\n",
      "Epoch 19/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1380 - acc: 0.9286 - val_loss: 0.5368 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.87368 to 0.87368, saving model to vgg16_custom.h5\n",
      "Epoch 20/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1855 - acc: 0.9048 - val_loss: 0.5721 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.87368\n",
      "Epoch 21/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1410 - acc: 0.9167 - val_loss: 0.6167 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.87368\n",
      "Epoch 22/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1343 - acc: 0.9315 - val_loss: 0.5270 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.87368\n",
      "Epoch 23/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1351 - acc: 0.9385 - val_loss: 0.4947 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.87368\n",
      "Epoch 24/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.1316 - acc: 0.9375 - val_loss: 0.4819 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.87368\n",
      "Epoch 25/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1157 - acc: 0.9385 - val_loss: 0.5977 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.87368\n",
      "Epoch 26/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1490 - acc: 0.9296 - val_loss: 0.5902 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.87368\n",
      "Epoch 27/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1400 - acc: 0.9276 - val_loss: 0.6015 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.87368 to 0.88421, saving model to vgg16_custom.h5\n",
      "Epoch 28/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1188 - acc: 0.9365 - val_loss: 0.5510 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.88421\n",
      "Epoch 29/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1165 - acc: 0.9454 - val_loss: 0.5415 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.88421\n",
      "Epoch 30/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1134 - acc: 0.9385 - val_loss: 0.6232 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.88421\n",
      "Epoch 31/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.1219 - acc: 0.9405 - val_loss: 0.4922 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.88421\n",
      "Epoch 32/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0905 - acc: 0.9494 - val_loss: 0.7406 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.88421\n",
      "Epoch 33/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1048 - acc: 0.9534 - val_loss: 0.6057 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.88421\n",
      "Epoch 34/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1147 - acc: 0.9325 - val_loss: 0.5912 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.88421\n",
      "Epoch 35/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1142 - acc: 0.9355 - val_loss: 0.6299 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.88421\n",
      "Epoch 36/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1218 - acc: 0.9395 - val_loss: 0.5646 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.88421\n",
      "Epoch 37/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1343 - acc: 0.9296 - val_loss: 0.5573 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.88421\n",
      "Epoch 38/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0981 - acc: 0.9494 - val_loss: 0.6296 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.88421\n",
      "Epoch 39/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0753 - acc: 0.9663 - val_loss: 0.7908 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.88421\n",
      "Epoch 40/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1040 - acc: 0.9514 - val_loss: 0.7010 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.88421\n",
      "Epoch 41/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0967 - acc: 0.9464 - val_loss: 0.6910 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.88421\n",
      "Epoch 42/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0833 - acc: 0.9643 - val_loss: 0.7277 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.88421\n",
      "Epoch 43/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0760 - acc: 0.9544 - val_loss: 0.7435 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.88421\n",
      "Epoch 44/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1246 - acc: 0.9454 - val_loss: 0.6124 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.88421\n",
      "Epoch 45/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1584 - acc: 0.9038 - val_loss: 0.5665 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.88421\n",
      "Epoch 46/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1637 - acc: 0.9186 - val_loss: 0.5066 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.88421\n",
      "Epoch 47/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.1232 - acc: 0.9266 - val_loss: 0.5981 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.88421\n",
      "Epoch 48/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1246 - acc: 0.9266 - val_loss: 0.7652 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.88421\n",
      "Epoch 49/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1008 - acc: 0.9494 - val_loss: 0.6791 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.88421\n",
      "Epoch 50/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0795 - acc: 0.9514 - val_loss: 0.7989 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.88421\n",
      "Epoch 51/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0666 - acc: 0.9673 - val_loss: 0.8397 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.88421\n",
      "Epoch 52/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0612 - acc: 0.9653 - val_loss: 0.7794 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.88421\n",
      "Epoch 53/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0647 - acc: 0.9712 - val_loss: 0.7624 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.88421\n",
      "Epoch 54/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0767 - acc: 0.9633 - val_loss: 0.8018 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.88421\n",
      "Epoch 55/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0654 - acc: 0.9683 - val_loss: 0.8305 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.88421 to 0.88947, saving model to vgg16_custom.h5\n",
      "Epoch 56/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0768 - acc: 0.9643 - val_loss: 0.7112 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.88947\n",
      "Epoch 57/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0792 - acc: 0.9683 - val_loss: 0.6930 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.88947\n",
      "Epoch 58/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1259 - acc: 0.9593 - val_loss: 0.7218 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.88947\n",
      "Epoch 59/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.1369 - acc: 0.9375 - val_loss: 0.4109 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.88947\n",
      "Epoch 60/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.1277 - acc: 0.9375 - val_loss: 0.5124 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.88947\n",
      "Epoch 61/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1333 - acc: 0.9286 - val_loss: 0.6130 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.88947\n",
      "Epoch 62/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0844 - acc: 0.9534 - val_loss: 0.8429 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.88947\n",
      "Epoch 63/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1019 - acc: 0.9613 - val_loss: 0.8053 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.88947\n",
      "Epoch 64/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0966 - acc: 0.9613 - val_loss: 0.9820 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.88947\n",
      "Epoch 65/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1050 - acc: 0.9484 - val_loss: 0.8628 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.88947\n",
      "Epoch 66/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0970 - acc: 0.9663 - val_loss: 0.9145 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.88947\n",
      "Epoch 67/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1013 - acc: 0.9633 - val_loss: 0.8931 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.88947\n",
      "Epoch 68/100\n",
      "63/62 [==============================] - 5s 83ms/step - loss: 0.0684 - acc: 0.9722 - val_loss: 0.8080 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.88947\n",
      "Epoch 69/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0703 - acc: 0.9712 - val_loss: 0.9325 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.88947\n",
      "Epoch 70/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0761 - acc: 0.9653 - val_loss: 0.7818 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.88947\n",
      "Epoch 71/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0761 - acc: 0.9692 - val_loss: 0.7253 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.88947\n",
      "Epoch 72/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0626 - acc: 0.9712 - val_loss: 1.0404 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.88947\n",
      "Epoch 73/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0653 - acc: 0.9692 - val_loss: 1.2008 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.88947\n",
      "Epoch 74/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1064 - acc: 0.9514 - val_loss: 1.1251 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.88947\n",
      "Epoch 75/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0699 - acc: 0.9683 - val_loss: 0.8539 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.88947\n",
      "Epoch 76/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.1014 - acc: 0.9534 - val_loss: 0.6544 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.88947\n",
      "Epoch 77/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0804 - acc: 0.9643 - val_loss: 0.8595 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.88947\n",
      "Epoch 78/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0837 - acc: 0.9653 - val_loss: 0.7264 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.88947\n",
      "Epoch 79/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0882 - acc: 0.9683 - val_loss: 0.7280 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.88947\n",
      "Epoch 80/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0823 - acc: 0.9573 - val_loss: 0.6296 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.88947\n",
      "Epoch 81/100\n",
      "63/62 [==============================] - 5s 84ms/step - loss: 0.0681 - acc: 0.9692 - val_loss: 0.8556 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.88947\n",
      "Epoch 82/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0773 - acc: 0.9712 - val_loss: 1.0087 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.88947\n",
      "Epoch 83/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0822 - acc: 0.9712 - val_loss: 0.8603 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.88947\n",
      "Epoch 84/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.1041 - acc: 0.9603 - val_loss: 1.0975 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.88947\n",
      "Epoch 85/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0870 - acc: 0.9464 - val_loss: 0.9900 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.88947\n",
      "Epoch 86/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0762 - acc: 0.9633 - val_loss: 1.0427 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.88947 to 0.88947, saving model to vgg16_custom.h5\n",
      "Epoch 87/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0826 - acc: 0.9573 - val_loss: 0.8361 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.88947\n",
      "Epoch 88/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0983 - acc: 0.9494 - val_loss: 1.2150 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.88947\n",
      "Epoch 89/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0829 - acc: 0.9563 - val_loss: 0.6891 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.88947\n",
      "Epoch 90/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0687 - acc: 0.9603 - val_loss: 0.9522 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.88947\n",
      "Epoch 91/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0675 - acc: 0.9563 - val_loss: 0.8821 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.88947\n",
      "Epoch 92/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0623 - acc: 0.9563 - val_loss: 0.9591 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.88947\n",
      "Epoch 93/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0546 - acc: 0.9653 - val_loss: 0.8912 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.88947\n",
      "Epoch 94/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0560 - acc: 0.9643 - val_loss: 0.8043 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.88947\n",
      "Epoch 95/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0438 - acc: 0.9762 - val_loss: 0.9046 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.88947\n",
      "Epoch 96/100\n",
      "63/62 [==============================] - 5s 85ms/step - loss: 0.0658 - acc: 0.9643 - val_loss: 0.9802 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.88947\n",
      "Epoch 97/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0478 - acc: 0.9782 - val_loss: 1.0611 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.88947\n",
      "Epoch 98/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0445 - acc: 0.9772 - val_loss: 0.9725 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.88947\n",
      "Epoch 99/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0453 - acc: 0.9821 - val_loss: 0.9117 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.88947\n",
      "Epoch 100/100\n",
      "63/62 [==============================] - 5s 86ms/step - loss: 0.0533 - acc: 0.9692 - val_loss: 0.9649 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.88947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13cec306748>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit_generator(train, steps_per_epoch=train_count/batch_size, validation_data=test, validation_steps=test_count/batch_size, epochs=100, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = load_model('vgg16_custom.h5')\n",
    "results = model_trained.evaluate_generator(test, steps=test_count/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.042738244172774\n",
      "Accuracy: 0.8894736823282744\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ' + str(results[0]))\n",
    "print('Accuracy: ' + str(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "img1 = image.load_img(\"data/test/other/0010.png\", target_size=(256, 256, 3))\n",
    "img2 = image.load_img(\"data/test/tiger/0019.png\", target_size=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(img1).reshape((1, 256, 256, 3))\n",
    "img2 = np.array(img2).reshape((1, 256, 256, 3))\n",
    "output1 = model_trained.predict(img1).argmax()\n",
    "output2 = model_trained.predict(img2).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(output):\n",
    "    if(output == 1):\n",
    "        print(\"Predicted result is a tiger\")\n",
    "    else:\n",
    "        print(\"Cannot detect tiger in the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot detect tiger in the image\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img1.reshape((256, 256, 3)))\n",
    "print(predict_label(output1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result is a tiger\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXmMXNd15r9TVV29r+yVzeYqSlwkipIoijIteZOtJcpImsS2NB5Z8RjDYCADCZABRkkwiDEzATyDSYIEM+OMAguWA8eKHMsQYStOZFnWTkqkRHFfmuLWO9n7Xl1Vd/7o4rjNe7/HbrKbXUK+H0B0835137v16vWpV++rc4455yCEEDOJLfYChBD5hwKDEMJDgUEI4aHAIITwUGAQQngoMAghPBYsMJjZfWZ2zMxazeyphdqPEGL+sYX4HoOZxQEcB/B5AG0A3gPwmHPu8LzvTAgx7yzUFcNWAK3OuY+ccykAzwF4aIH2JYSYZxILtN1mAOdm/L8NwB3swcXJhKsoKQxqk6kpupN0Jny1k85k6ZyoK6Q4VYB4zKgWM7LNiH0lYjwmR13EjZPnDABT2Su4+uNPC4jY3JVeZ8bI807E+UIKIrRkgh/HmPF57DBanP9JsPMNAKbSaaoVFxfzbU6l+DbJuZ/J8vM7ao0Z5y445+roA2awUIEh9Ir82orNbAeAHQBQXpzEl+9eF9zQR+d66E56ByfC40PjdM5UKkO18ogTqaaYa4Xx8DZjGb6vmtISqqVT/MU9NDBJtfYxHkRZBIjF+R9WJiJCRQbfiONYUVYUHK8tL6BzmqqSVGuuKaNaSYKH+qE0CVAV/O+mbyR8vgFA5/l+qm3csJ5q57s6qNbd3hYcHxjh50B/xBp7x1NnqHgJC/VRog1Ay4z/LwPwa0fAOfe0c26Lc25LcXKh4pMQ4kpYqMDwHoC1ZrbKzJIAHgWwc4H2JYSYZxbkrdo5lzazbwD4J0x/dH/GOXdoIfYlhJh/Fuwa3jn3EoCXFmr7QoiFQ998FEJ45MVdPwdgKhu+g7zu9s/QebGy+uD4/gP8e1R733mDai1LqISW+vDddACYmgq7AePj3CXoGOJ3jzMZfjc9G2GqVhTyOF9OXJBYxJ37vsEhqqVjEa5EhO87OhJ2jIaHxuicjm7+vM7U8Dv0lRWlVGPu89IkPwm6iAsGAMtu2ES17fc+SLUXfvQPVDt49mBwfCrCESq4YiP519EVgxDCQ4FBCOGhwCCE8FBgEEJ4KDAIITwUGIQQHnlhV5aUlePW7XcFtZvv+TKdlymqDo4/MMQTWr7/139JtX98gVtHbf3ceiwuCicAVVaU0znZIm45Zae45ZQEn5ca48lj/YMDwfGCQn4KVNdwuy8qY7AgIjFrYjKchTgakQDWNzhKte5+biF29PN5LQ1V4X0d5F/QXdK8kmr33nc/1YbG+BrPDwxTLWNh3zfKkCyIc3Uiwua8FF0xCCE8FBiEEB4KDEIIDwUGIYSHAoMQwiMvXIlEMon65SuCWldfL53X198ZHK8p5k/rN//VfVQrKuB39ffsfodqZcVhV2JpfSWdMz7M75gPD3BtcITfWZ5w/HnHLDxvIqL8XGFEGby448cqY7z+YSkp7VZTyR2Q8hJeKm4w4jiuWrWMaps2hs+3qSm+9sYVvERbNc+xw+njp6g2PhB2iwDQ4p8x8DVWJPl7/TB/yQL7EEKIS1BgEEJ4KDAIITwUGIQQHgoMQggPBQYhhEde2JUum0FqIlxfsDLBLbNiCyfeDPVyi3MqdYFqm5fzpKfa8aVUO9sVtpx6OngyVzrGOy+hOJzgAwCxSb7Nhnre3SobD3dz6urhx2p8grdPKyoKtxQEgPqGiOKZLvyaxRL8VFxaVku1ukw4kQ4AVqxsoVp1dXib1dUVdI4l+fE9c+o41c618wZQIxMRtT9J68NYRBpVPKaaj0KIBUKBQQjhocAghPBQYBBCeCgwCCE8FBiEEB55YVeOj43g4Pvh7MVVVkbnlZU2BsfTjmefjY3yGnu97W1U6+w6T7UMwql1S5Y20zmjjtuV/cPcwqpp5POWVPBjdbqtJziezXI7eDLDra+uiJZyiTKeKVmUCL8XJdN8HU113EJMpXm26fnzg1Tr7wuvP6pe5bY7t1Jt47rrqDYcYfu+uXsX1bLsPI7xP9vecX4c54KuGIQQHgoMQggPBQYhhIcCgxDCQ4FBCOFxVa6EmZ0GMAwgAyDtnNtiZjUA/h7ASgCnAXzJOcczf4QQecd82JWfcc7NTFl8CsArzrlvmdlTuf//p6gNuEwW6eGRoNbX2U3njRaF7bTzXV10Tkk5Lyxa2ng91RoLecbg4FC4IOk7uz+gc0bHJ6l2w7o1fF/D3J472cYzR5sawtmEsTg/BQZGuc3WOxh+vQBgYpK3m1tSEbYebZIfj2FyfAEgWcatzIbl3EJcd+Om4PjkKLc4ewf4ueiO8dZ2d27eSLWqKp5J+7/+7/eD46dOnaVzJklbu2m4jX8pC/FR4iEAz+Z+fxbAwwuwDyHEAnK1gcEB+Gcz22tmO3JjDc65TgDI/awPTTSzHWa2x8z2jEW8wwghrj1X+1Fiu3Ouw8zqAbxsZkdnO9E59zSApwGgaUn5/FSXEELMC1d1xeCc68j97AHwYwBbAXSbWRMA5H6Gv4srhMhbrjgwmFmpmZVf/B3AFwAcBLATwBO5hz0B4MWrXaQQ4tpyNR8lGgD82MwubufvnHM/M7P3ADxvZl8HcBbAF69+mUKIa8kVBwbn3EcAbg6M9wL43Fy2VVBQgKaG4D1KVFVyO2c0FbZmzp1tp3OWrQzvBwBWNvKio1WlvPipnQ0X+6wkdioA3L6RW6MrVy2n2pDx4qeTWX4BeObkseD4VJb3TqypKKZaUx0vnNsWkYna1RW2/BqX8Nc5keTHfmyK288FZXVUW7nxtuB4UbhmLgDgw7deo9o//fxnVFt25CTVtt15J9Wubwq/1p2nPqJz4hEfAmZvVuqbj0KIAAoMQggPBQYhhIcCgxDCQ4FBCOGRFzUf05k0evvDySsvv/0cnbf2pnANvlu23ETnVFTwmonZwXNUO99+ims95C58QbgWJAAsvX4D1TZt3Ua1NRu3U+0Xr++mWjYRrsPoCnjbtfH+TqqVF/JkrtFBflpl4mGnpiTOtzc5zBObxh1PsCqJ8/qH6clwzcfXdn1I57z4w51UmxwJt1gEgIOHW6k2Psnre267Y3NwPFbArZO33uWJexjn+/L2MetHCiH+xaDAIITwUGAQQngoMAghPBQYhBAeCgxCCI+8sCtTqTROnwvXaTx1JpygBAAZYgeu27iSzokZt2zOtJ2mWnaKV5m6MBSujfj6Xr69uut58tId962i2sET/HisvI4nZpWS2oKbbw0nEwFAXxff14UObt/2X3idaqlUuC5wMsvtyomJcapVVfPEt+IE32Y8E64xmR7jtSzjPF8LpaW8PeCE8XW0R7TR++xvhOtSbrjjLjpnJPvXVHvjDd4O71J0xSCE8FBgEEJ4KDAIITwUGIQQHgoMQggPBQYhhEde2JWFhYVYfX24nVh5QzOdt/6mW4Lj8Yjqdm+/8S7VBi60Ue3RL/GGWtXLwhbc/laenbh3L8/iK/je31Htl6/yuoPNzcuoVrUkbOv926/8GzpnzXW8tVpdNa+nODnO7bm9b/0yON7Vx9vrVRTzmo/9Xbw7wZsvv0q1lhXh821VcyOd8/CDD1LtwgVuP7+3l59zroDXzowVhbWSMj5n65ZbqSa7UghxVSgwCCE8FBiEEB4KDEIIDwUGIYSHAoMQwiMv7MpEQRy1DeF2XEvXrKHzYolwUcwLPdz66urg9tb2T2yh2okzHVQbGQvbo088ztt2Pvu3P6TaySMHqPbbjzxAtQMHj1BtajycofjeO+/ROatWLKXasqYlVNu2LVzEFABa94ctxBoLtxsEgPgkz3isKeOFURNxnkl7et+e4PhUWQ2d80bEsaqs4scjWciLAo9Pcms3kw3/efb3cWt05TJuWc8FXTEIITwUGIQQHgoMQggPBQYhhIcCgxDCQ4FBCOFxWbvSzJ4B8CCAHufcjbmxGgB/D2AlgNMAvuSc6zczA/CXAB4AMAbgd5xz7192EQVJ1DUtD2rZeDGdNzgStuAampvonBs3raNaQwMvLPrya9yq2vnSL4Pjj/4Wz8b7zF3hvpsA8Obe/VSLJbj1tfU2Xti1q/1kcLz7LH95JoZ4tmlN5WeotqaFH/+tm8IFa1PneXHZZIKfpv1DvEjvQN8w1U4cDh/jo318eyU1YUsdANavW0G1XW++RbXOC7z35sRE2Mq8bu1qOqcwwhqdC7O5YvgugPsuGXsKwCvOubUAXsn9HwDuB7A2928HgG/PyyqFENeUywYG59zrAPouGX4IwLO5358F8PCM8e+5aXYBqDIz/vYhhMhLrvQeQ4NzrhMAcj/rc+PNAGb2km/LjQkhPkbM983HUEsOF3yg2Q4z22Nme4aGx+Z5GUKIq+FKA0P3xY8IuZ8XExDaALTMeNwyAMEkA+fc0865Lc65LRXlJVe4DCHEQnClgWEngCdyvz8B4MUZ41+1abYBGLz4kUMI8fFhNnblDwB8GkCtmbUB+BMA3wLwvJl9HcBZABfTCF/CtFXZimm78muzWYTFEkiUhHsrDoxw+8jFw1ca5TW8UGlXH7cd+4aOU+2BR75EtZNt4WKwJUme+beskWfxvfqLS+/1/oqjH/DMy7vuuoNqFxDOUBwaOEvnHDt6lGrvvMMt1a/9Di8w29gStiuPRfTJjBdzy7p6KS/eemGolWr794UzUQvq19I5n97+Kaod27+XaoM956lWXcnXP9Af7mtZXMqLwVZU8/NqLlw2MDjnHiPS5wKPdQCevNpFCSEWF33zUQjhocAghPBQYBBCeCgwCCE88qLmo7MY0vGyoHa2+zSd19AUrm9XUMqToYYmQt/Bmqa8LLwGALhu4+18HctfDo6PpTN0zuAwT56prePrLyzhXwYbGeW1Lm/ZfH9wvLq6i86paWyn2hvvvk61//zf/gvV7r0tfNd/VQ1/j8o4/poVJHityJYVLVRbPxpOUDp6jjsIh999h2oTw9xJQoafB/EinvTUTVyJySleJzKR5O385oKuGIQQHgoMQggPBQYhhIcCgxDCQ4FBCOGhwCCE8MgPuxIxpC1s2zSvDCfdAMCNm24Jjg/0hZOaAKC4nFuB93zhXqoVlfEWZKWVYe3O7bfSObWVlVQbAq8t2HZiH9VOffgu17Lhlmw1S+qD4wBwz7ZtVCsrCNfbBIDnnnuBah1nTgfHV1Xyej5uapJqfed58m5JIU9iu/OWlcHxWOw0ndN69AOqVUa8nsOkPSAAFBfxBDErDGupNLcrYzFu384FXTEIITwUGIQQHgoMQggPBQYhhIcCgxDCQ4FBCOGRF3ZlPJ5AWVXYNqsq4Nli5WVhi+jsmWBhagBAsqSCao0tvPVXbQ239W64bn1wvLCY155cve4mqt3Yl6JaRTm3xXrbT1CtFOF2bRWJCTpn8AzPJlxexC24B7esolpqPFx7cnyMZ5vGjVtwY+N8/ZPxAaqhPGwFLm/g9RQ7zg9RrW+YaxOT3G5NGH9vrioNrzGT5XVQ08atzLmgKwYhhIcCgxDCQ4FBCOGhwCCE8FBgEEJ4KDAIITzywq40iyFREM6u7OrixUobG8IZeWOjvGDqqtVrqLa0OVxcFgBGx/g2jx4Nt7b77jPfpXM+dfd2qhVFZAUuaeAWaO3KDVTLDpMip2lu6Y1luAWXKOSnzvVrl1NtdDhc4HRwuJfO6ekLW5wAkInINCyv4Gtkr2fMeIPlmupSqk1Mhp8XADTXhtsvAsDZw4eodnJNOLP4ttu51T04wNcxF3TFIITwUGAQQngoMAghPBQYhBAeCgxCCA8FBiGER17YlelMGv394QKuI8PhrMCL80IMDnLLpr6O233xAn44ptI843H9jWGb0GK85+K//u3fotptt/Eisr29vNDtL155hWqnBsLWY0kVtxZLCnjmYqFx+7aklL9mtY01wfFzbfzY73v/JN9XEc+WTRQWUC0ZD2dsFldwa/HGm3jWaGUFL0o7OMjt1rEpfq7ue29XcPy2O7fwdVTz4zEXdMUghPC4bGAws2fMrMfMDs4Y+6aZtZvZvty/B2Zof2hmrWZ2zMx4PXYhRN4ymyuG7wK4LzD+F865zbl/LwGAmW0A8CiAjbk5/8csosqGECIvuWxgcM69DqBvltt7CMBzzrlJ59wpAK0Atl7F+oQQi8DV3GP4hpntz33UuNg6qRnAuRmPacuNeZjZDjPbY2Z7hof4d/KFENeeK3Ulvg3gvwJwuZ9/BuDfAQjdhnehDTjnngbwNACsvu46Rx6GpqVL6SImSL2/1tZWOqe6hreaO3nqFNVKSP09APjK448Hx2uX8DvE+/cdoNo7u8N3owGgOqLmo8uEjyEArL8x7HSUF/P3hv7Oo1TrPHuWassbeIs9I+9FdU2NdM6mW/hzPnyYr2N8KsKVyIaT9kZHeAJb06omqpVX8RqYqSnu7qxf10K1E53hOpinTn5E52zZyh2tuXBFVwzOuW7nXMY5lwXwN/jVx4U2ADOf6TIAvDKrECIvuaLAYGYzQ+cjAC46FjsBPGpmhWa2CsBaALzTqhAiL7nsRwkz+wGATwOoNbM2AH8C4NNmthnT1/+nAfwuADjnDpnZ8wAOA0gDeNI5l1mYpQshForLBgbn3GOB4e9EPP5PAfzp1SxKCLG46JuPQggPBQYhhEdeJFHFYnGUlIQtqZoqntRSSNrXxbLctpsc4Qk+qUluK3344ft83lg4Seb2iGSobERMHpvkdQwLkuHEMQBobObWV3EybMPFMrx9WmnLdVSrq+at3GIpnhjU2x22hM3x12xJA7crS85z+7mzn7+epbWk5SBJzAOArh5eH/O2uz9PtazjLeWOHA/XCwWAnlT4WJUUc+s8PsVt07mgKwYhhIcCgxDCQ4FBCOGhwCCE8FBgEEJ4KDAIITzywq6MJxKoqq0NapWVEdmE2bCtd/9vPsj3ZbwOY3U1t75qP3EX1Y63hmsSvrV7D51TGZHVuHkDb6PnJnlO2sEP+P7a23uC4yWl/PhuuYPXFmy5nluxQ33dXEuF6/YMps4FxwFgKsPt28f+/X+gWt84P71/8dOfBMdH+0grPwCfv+ezVPvCw49Q7dQZng3ZNsTt0ezBcOZo22m+vfYTH1JtLuiKQQjhocAghPBQYBBCeCgwCCE8FBiEEB4KDEIIj7ywK82AWCKcXZc1blU50gKuppEXFnUR1lcywsosTYYzOQFg6+23BceX1oYLjgLA4V0/pdrJt/dSzYZ6qTbRxq22yb5wi73TA9wuO3poP9U+8dl7qLZ23UaqlTWFtfLGdXQOz7sEKhtXUG11Y7BAOQCgqqYhOP7B+x/QOTfc/imqtffzln0Hj5+h2p4PDlNtciicpdr5Ec/IHBvn65gLumIQQngoMAghPBQYhBAeCgxCCA8FBiGEhwKDEMIjL+zKdGoKvR3hrMHuLM8mLCwqC47XR9hUqRQ3v6aMF+3EYCeVhtvDPR47juymc1wP75OZSvOCnhP93K4cPMftyuG+cN+f/l7+nPvHeRbfhTO8Z+SKddx6bFi2Mji+cg2fs+r6DVTrPs8Lz/7slV9S7eWXfx4cT03y4zE2xbX6Wp6Z+9Mf/5Bqxw5ye7SmMGyfj0ecH0sjjiPA93UpumIQQngoMAghPBQYhBAeCgxCCA8FBiGER164ElNTKXS2he9y9w2G278BQCYTXn5dFb/j39TAW95lHW9BNkScBwA4f/jd4PhUD0+esYjWcAPDo1Qb6ePzBkmiFABkXLjWYklEO7/CkgKqVRfwdVw48h7VMNIVHB4bCNekBICRMd5qLp3g7dqOHG+lWmll+Dy4cSWvt9ncvIxqdVVhhwwAYin+esbHuKtSVlwSHE/E+Ot80+ZNVHv+J+E6lyF0xSCE8FBgEEJ4KDAIITwuGxjMrMXMXjWzI2Z2yMx+LzdeY2Yvm9mJ3M/q3LiZ2V+ZWauZ7Tcz3oBACJGXzOaKIQ3gD5xz6wFsA/CkmW0A8BSAV5xzawG8kvs/ANwPYG3u3w4A3573VQshFpTLBgbnXKdz7v3c78MAjgBoBvAQgGdzD3sWwMO53x8C8D03zS4AVWbWNO8rF0IsGHOyK81sJYBbAOwG0OCc6wSmg4eZ1ece1gxgZr+xttwYzULKZDIYGAnbkjV13F7saQtbXPvf5slLw3W8rmNqkNucoxFt12wsbN0lI4oVplLcgktNcDtqcoTbhAnw51ZTE7a+yst5DcxYktuVdQ3h7QHAqQ5ed3Dt6urw+BaeKLX65k9QLVG2lGqfvIfXaIxbOKmsMM7/JCbGh6l26AN+ziXj/Hhcv4YnX61Zsyo4Xt3MLdU1G2+k2lyY9c1HMysD8CMAv++cG4p6aGDM+xMxsx1mtsfM9oyOcp9XCHHtmVVgMLMCTAeF7zvnXsgNd1/8iJD7efHtuw1Ay4zpywB4udPOuaedc1ucc1tKS0uvdP1CiAVgNq6EAfgOgCPOuT+fIe0E8ETu9ycAvDhj/Ks5d2IbgMGLHzmEEB8PZnOPYTuAxwEcMLN9ubE/AvAtAM+b2dcBnAXwxZz2EoAHALQCGAPwtXldsRBiwblsYHDOvYnwfQMA+Fzg8Q7Ak1e5LiHEIqJvPgohPPIiu3JidARH330jqG3bsp7OKxsJ1zhckbxA50y18YzHsV5eMzE1GlEPkhzGkRS3AsfHeWu4qXRExmOCW4hVVbwlXlVtZXA8E9ECME0sPQBY0sBvGGcK+ftNQ104C7EgzWtZnt7/CtWyibD9CQDJEt5WsLggfIxPtrfROSdP8tZw6Yg6jLdt4jVIhwd5dmh57drgeO3yzXROorCcanNBVwxCCA8FBiGEhwKDEMJDgUEI4aHAIITwUGAQQnjkhV2ZiGfRWBrOGuz7aC+dF58IZyhmR/rpnPHBiKKjQzwLboInNSJZmgyOx0t5BqKBZ1C6sQitlNuViboari0Ja8mIDMrxKf6krYJnBTZW8m1WVFaE9zUQLhILAAcO7KJaRzdPwNtw80aqFRaFT/3uDv7t/eIk/3O5/eabqdZ9vo9qHx0/R7UPD4afd9US3h6woWl+KhzoikEI4aHAIITwUGAQQngoMAghPBQYhBAeCgxCCI+8sCtLyipw892fDWqTQzzrLpYKl4m40M0tSTd2HdWSY9zmbD1+gmotG8K2WEGCH96O0zzLs++MVwnvV9oEz3isawoXDwWAmtXrguPF5dziPHz8JNWsnvdxnJziGZsdpGfn5Ch/nT84wbNl6yPWMTQR7tcJAL3n2oPjo/3cWqwp4/0pd73ObfWDh3kPzfZufs5NToQzNgeL+fbOl3GLfC7oikEI4aHAIITwUGAQQngoMAghPBQYhBAeCgxCCI+8sCsTySLUNIfttB7Hrbtdb70dHL/9jjvonE2bb6Lagfd5/8GfvP801eqKwhZoSwsvArp54yep1nD2GNVee/V1qh3v4P0wY3XhoqNVRTxL0qq47dg+yDNRqyvChWcBoKstbM8dOXCUzhkc5RZt0QC3F/f3hC1JAEiNh21Tl+WFeLuy3AYH+Bqdi7CYa3nB2kQibD3G4hHv58YtWpzjvTe9fcz6kUKIfzEoMAghPBQYhBAeCgxCCA8FBiGER164EmZxFBdWBbV0hreNK6tpDI4XVtfROVXLeKJR8xhvM2al/E77h63hhKgz54fonK98+YtUq28OtyYDgEPHeG3E118LuzQAcPDgR+F91dfTORWkliUAFBZwx6KogPVABibHw8e4IsbdgKpl/PWMxfi+zHhCUTwZvnsfub0sf84uw1sOIh3hWGQitFh4jekI5yHCVAHAz51L0RWDEMJDgUEI4aHAIITwUGAQQngoMAghPC4bGMysxcxeNbMjZnbIzH4vN/5NM2s3s325fw/MmPOHZtZqZsfM7N6FfAJCiPlnNnZlGsAfOOfeN7NyAHvN7OWc9hfOuf8588FmtgHAowA2AlgK4Odmdr2LyiRxQJrUCRwf5+3aNt98a3C8qLCUzunrHaRaWUk11RrqeULUJLGj1q2/gc7Zvftdqo0NRLTYm+DHo6mOW6qNS8LPraSA+1vxOLdv4xYxj7t6KCwhNmGcW3DxRERbvgKehBRl3aWZ9WjcrpxKc0syO8VP73SWz3PgBytuYS0RNSfJLea5cNkrBudcp3Pu/dzvwwCOAOB/JcBDAJ5zzk06504BaAWwdT4WK4S4NszpHoOZrQRwC4CL+cnfMLP9ZvaMmV18S2oGMLNTZxsCgcTMdpjZHjPbMzA4MOeFCyEWjlkHBjMrA/AjAL/vnBsC8G0AawBsBtAJ4M8uPjQw3buoc8497Zzb4pzbUlUZ/tajEGJxmFVgMLMCTAeF7zvnXgAA51y3cy7jnMsC+Bv86uNCG4CWGdOXAeDVVoQQecdsXAkD8B0AR5xzfz5jvGnGwx4BcDD3+04Aj5pZoZmtArAWAL/TJoTIO2bjSmwH8DiAA2a2Lzf2RwAeM7PNmP6YcBrA7wKAc+6QmT0P4DCmHY0nIx0JIUTeYc5FpmNdm0WYnQcwCoD3IssfavHxWCfw8Vmr1jn/hNa6wjnHU1VnkBeBAQDMbI9zbstir+NyfFzWCXx81qp1zj9Xu1Z9JVoI4aHAIITwyKfAwBs35Bcfl3UCH5+1ap3zz1WtNW/uMQgh8od8umIQQuQJix4YzOy+XHp2q5k9tdjruRQzO21mB3Kp5XtyYzVm9rKZncj95GmZC7euZ8ysx8wOzhgLrsum+avcMd5vZuG01Gu71rxL248oMZBXx/WalEJwzi3aPwBxACcBrAaQBPAhgA2LuabAGk8DqL1k7H8AeCr3+1MA/vsirOtuALcCOHi5dQF4AMA/YjqPZRuA3Xmw1m8C+I+Bx27InQeFAFblzo/4NVpnE4Bbc7+XAzieW09eHdeIdc7bMV3sK4atAFqdcx8551IAnsN02na+8xCAZ3O/Pwvg4Wu9AOfc6wAu7ejK1vUQgO+5aXYBqLrkK+0LClkrY9HS9h0vMZBXxzVinYw5H9PFDgyzStH8vwsjAAABhklEQVReZByAfzazvWa2IzfW4JzrBKZfJAC8OcO1ha0rX4/zFaftLzSXlBjI2+M6n6UQZrLYgWFWKdqLzHbn3K0A7gfwpJndvdgLugLy8ThfVdr+QhIoMUAfGhi7Zmud71IIM1nswJD3KdrOuY7czx4AP8b0JVj3xUvG3M+exVvhr8HWlXfH2eVp2n6oxADy8LgudCmExQ4M7wFYa2arzCyJ6VqROxd5Tf8fMyvN1bmEmZUC+AKm08t3Angi97AnALy4OCv0YOvaCeCrubvo2wAMXrw0XizyMW2flRhAnh1Xts55PabX4i7qZe6wPoDpu6onAfzxYq/nkrWtxvTd3A8BHLq4PgBLALwC4ETuZ80irO0HmL5cnML0O8LX2bowfSn5v3PH+ACALXmw1r/NrWV/7sRtmvH4P86t9RiA+6/hOj+J6Uvs/QD25f49kG/HNWKd83ZM9c1HIYTHYn+UEELkIQoMQggPBQYhhIcCgxDCQ4FBCOGhwCCE8FBgEEJ4KDAIITz+H8GD0jiW0j+QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img2.reshape((256, 256, 3)))\n",
    "print(predict_label(output2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
