{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import syft as sy\n",
    "sy.create_sandbox(globals(), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = grid.search(\"#boston\", \"#data\", verbose=False, return_counter=False)\n",
    "boston_target = grid.search(\"#boston\", \"#target\", verbose=False, return_counter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = boston_data['alice'][0].shape[1]\n",
    "n_targets = 1\n",
    "model = th.nn.Linear(n_features, n_targets)\n",
    "optimizer = th.optim.SGD(params=model.parameters(),lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bob', 'theo', 'jason', 'alice', 'andy', 'jon']\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "for worker in boston_data.keys():\n",
    "    dataset = sy.BaseDataset(boston_data[worker][0], boston_target[worker][0])\n",
    "    datasets.append(dataset)\n",
    "\n",
    "# Build the FederatedDataset object\n",
    "dataset = sy.FederatedDataset(datasets)\n",
    "print(dataset.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = sy.FederatedDataLoader(dataset, batch_size=4, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/127 (0%)]\tLoss: 140538.093750\n",
      "Train Epoch: 1 [80/127 (16%)]\tLoss: 4347.361328\n",
      "Train Epoch: 1 [160/127 (31%)]\tLoss: 12499.462891\n",
      "Train Epoch: 1 [240/127 (47%)]\tLoss: 880.233459\n",
      "Train Epoch: 1 [320/127 (63%)]\tLoss: 375.544556\n",
      "Train Epoch: 1 [400/127 (79%)]\tLoss: 18790.222656\n",
      "Train Epoch: 1 [480/127 (94%)]\tLoss: 5453.257324\n",
      "Total loss 836503.0455322266\n",
      "Train Epoch: 2 [0/127 (0%)]\tLoss: 3110.096436\n",
      "Train Epoch: 2 [80/127 (16%)]\tLoss: 530.349121\n",
      "Train Epoch: 2 [160/127 (31%)]\tLoss: 8554.211914\n",
      "Train Epoch: 2 [240/127 (47%)]\tLoss: 939.123413\n",
      "Train Epoch: 2 [320/127 (63%)]\tLoss: 227.793640\n",
      "Train Epoch: 2 [400/127 (79%)]\tLoss: 9958.423828\n",
      "Train Epoch: 2 [480/127 (94%)]\tLoss: 8097.923340\n",
      "Total loss 383324.6177062988\n",
      "Train Epoch: 3 [0/127 (0%)]\tLoss: 2684.269287\n",
      "Train Epoch: 3 [80/127 (16%)]\tLoss: 304.415710\n",
      "Train Epoch: 3 [160/127 (31%)]\tLoss: 7982.725586\n",
      "Train Epoch: 3 [240/127 (47%)]\tLoss: 927.968689\n",
      "Train Epoch: 3 [320/127 (63%)]\tLoss: 200.260513\n",
      "Train Epoch: 3 [400/127 (79%)]\tLoss: 8837.889648\n",
      "Train Epoch: 3 [480/127 (94%)]\tLoss: 8309.238281\n",
      "Total loss 352244.46026420593\n",
      "Train Epoch: 4 [0/127 (0%)]\tLoss: 2608.320068\n",
      "Train Epoch: 4 [80/127 (16%)]\tLoss: 288.430664\n",
      "Train Epoch: 4 [160/127 (31%)]\tLoss: 7846.917969\n",
      "Train Epoch: 4 [240/127 (47%)]\tLoss: 907.077698\n",
      "Train Epoch: 4 [320/127 (63%)]\tLoss: 188.113388\n",
      "Train Epoch: 4 [400/127 (79%)]\tLoss: 8643.546875\n",
      "Train Epoch: 4 [480/127 (94%)]\tLoss: 8127.454590\n",
      "Total loss 345345.026556015\n",
      "Train Epoch: 5 [0/127 (0%)]\tLoss: 2583.450195\n",
      "Train Epoch: 5 [80/127 (16%)]\tLoss: 297.438995\n",
      "Train Epoch: 5 [160/127 (31%)]\tLoss: 7779.008789\n",
      "Train Epoch: 5 [240/127 (47%)]\tLoss: 886.003418\n",
      "Train Epoch: 5 [320/127 (63%)]\tLoss: 179.151077\n",
      "Train Epoch: 5 [400/127 (79%)]\tLoss: 8582.194336\n",
      "Train Epoch: 5 [480/127 (94%)]\tLoss: 7904.950195\n",
      "Total loss 341865.24510765076\n",
      "Train Epoch: 6 [0/127 (0%)]\tLoss: 2567.588623\n",
      "Train Epoch: 6 [80/127 (16%)]\tLoss: 309.970428\n",
      "Train Epoch: 6 [160/127 (31%)]\tLoss: 7724.863281\n",
      "Train Epoch: 6 [240/127 (47%)]\tLoss: 866.064941\n",
      "Train Epoch: 6 [320/127 (63%)]\tLoss: 171.515289\n",
      "Train Epoch: 6 [400/127 (79%)]\tLoss: 8539.103516\n",
      "Train Epoch: 6 [480/127 (94%)]\tLoss: 7692.873047\n",
      "Total loss 339051.07812309265\n",
      "Train Epoch: 7 [0/127 (0%)]\tLoss: 2554.259521\n",
      "Train Epoch: 7 [80/127 (16%)]\tLoss: 322.706879\n",
      "Train Epoch: 7 [160/127 (31%)]\tLoss: 7675.948242\n",
      "Train Epoch: 7 [240/127 (47%)]\tLoss: 847.359009\n",
      "Train Epoch: 7 [320/127 (63%)]\tLoss: 164.804077\n",
      "Train Epoch: 7 [400/127 (79%)]\tLoss: 8496.958984\n",
      "Train Epoch: 7 [480/127 (94%)]\tLoss: 7496.776855\n",
      "Total loss 336464.5510559082\n",
      "Train Epoch: 8 [0/127 (0%)]\tLoss: 2542.314453\n",
      "Train Epoch: 8 [80/127 (16%)]\tLoss: 335.055847\n",
      "Train Epoch: 8 [160/127 (31%)]\tLoss: 7630.615234\n",
      "Train Epoch: 8 [240/127 (47%)]\tLoss: 829.810730\n",
      "Train Epoch: 8 [320/127 (63%)]\tLoss: 158.849426\n",
      "Train Epoch: 8 [400/127 (79%)]\tLoss: 8453.081055\n",
      "Train Epoch: 8 [480/127 (94%)]\tLoss: 7315.706055\n",
      "Total loss 334014.7919406891\n",
      "Train Epoch: 9 [0/127 (0%)]\tLoss: 2531.433105\n",
      "Train Epoch: 9 [80/127 (16%)]\tLoss: 346.871552\n",
      "Train Epoch: 9 [160/127 (31%)]\tLoss: 7588.298828\n",
      "Train Epoch: 9 [240/127 (47%)]\tLoss: 813.331299\n",
      "Train Epoch: 9 [320/127 (63%)]\tLoss: 153.536880\n",
      "Train Epoch: 9 [400/127 (79%)]\tLoss: 8407.097656\n",
      "Train Epoch: 9 [480/127 (94%)]\tLoss: 7148.002930\n",
      "Total loss 331668.2929954529\n",
      "Train Epoch: 10 [0/127 (0%)]\tLoss: 2521.445312\n",
      "Train Epoch: 10 [80/127 (16%)]\tLoss: 358.097748\n",
      "Train Epoch: 10 [160/127 (31%)]\tLoss: 7548.646973\n",
      "Train Epoch: 10 [240/127 (47%)]\tLoss: 797.836853\n",
      "Train Epoch: 10 [320/127 (63%)]\tLoss: 148.773575\n",
      "Train Epoch: 10 [400/127 (79%)]\tLoss: 8358.987305\n",
      "Train Epoch: 10 [480/127 (94%)]\tLoss: 6992.127441\n",
      "Total loss 329404.27191352844\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss_accum = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        model.send(data.location)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data)\n",
    "        loss = ((pred - target)**2).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get()\n",
    "        loss = loss.get()\n",
    "        loss_accum += float(loss)\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * data.shape[0], len(train_loader),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "            \n",
    "    print('Total loss', loss_accum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bob': [(Wrapper)>[PointerTensor | me:5200960656 -> bob:88941961208]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...,\n",
       "  (Wrapper)>[PointerTensor | me:18203385874 -> bob:35203648386]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...],\n",
       " 'theo': [(Wrapper)>[PointerTensor | me:56014661270 -> theo:2038860180]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...,\n",
       "  (Wrapper)>[PointerTensor | me:37685566526 -> theo:81238316848]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...],\n",
       " 'jason': [(Wrapper)>[PointerTensor | me:28942661533 -> jason:80498334063]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...,\n",
       "  (Wrapper)>[PointerTensor | me:57623678057 -> jason:49315651143]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...],\n",
       " 'alice': [(Wrapper)>[PointerTensor | me:77998773816 -> alice:55047605352]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...,\n",
       "  (Wrapper)>[PointerTensor | me:59914006277 -> alice:68999669909]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...],\n",
       " 'andy': [(Wrapper)>[PointerTensor | me:52414333755 -> andy:39201999992]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...,\n",
       "  (Wrapper)>[PointerTensor | me:43208013433 -> andy:15443237630]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([84, 13])\n",
       "  \tDescription: .. _boston_dataset:...],\n",
       " 'jon': [(Wrapper)>[PointerTensor | me:49593079673 -> jon:49112533019]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([86, 13])\n",
       "  \tDescription: .. _boston_dataset:...,\n",
       "  (Wrapper)>[PointerTensor | me:93355749123 -> jon:17224566273]\n",
       "  \tTags: #housing #boston #boston_housing .. _boston_dataset: #data \n",
       "  \tShape: torch.Size([86, 13])\n",
       "  \tDescription: .. _boston_dataset:...]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
